# Cardano Stake Pool Simulation

This repository contains a multi-round simulation of Cardano stake pools and delegators powered by large language models (LLMs). Pool operators adjust their parameters in response to market signals, delegators rebalance their stake, and the simulation records the resulting network dynamics round by round.

---

## ğŸš€ At a Glance
- Multi-round environment where delegators and pool operators react to shared network briefings.
- Pool operators and delegators are persona-driven agents that call an OpenAI-compatible LLM to justify and execute their decisions.
- Delegator wealth follows a configurable power-law distribution; stake can be split across multiple pools every round.
- Each run logs full round transcripts, JSON state history, and inequality metrics (Gini coefficients) for later analysis.

---

## ğŸ“‚ Project Layout
- `main.py` â€“ CLI entry point; parses arguments and starts a simulation run.
- `simulation.py` â€“ Orchestrates rounds, builds network briefings, aggregates rewards, and streams logs/results to `results/<timestamp>/`.
- `pool_agents.py` â€“ Persona-aware stake pool operators that revise pledge, margin, and cost after each round via an LLM call.
- `user_agents.py` â€“ Delegator personas that decide how to split stake across pools. Ensure this module is available before running the simulation.
- `constants.py` â€“ Network-wide parameters (`TOTAL_REWARDS`, `S_OPT`, `A0`) used in the Cardano reward formula.

---

## ğŸ“¦ Requirements
- Python 3.10 or newer.
- Dependencies listed in `requirements.txt` (`pip install -r requirements.txt`).  
  If your `user_agents.py` relies on `pydantic`, install it alongside the listed packages.
- An OpenAI-compatible endpoint. By default the code targets a local Ollama server.

---

## ğŸ”§ Setup
1. **Clone the repository**
   ```bash
   git clone <repo-url>
   cd Cardano
   ```
2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```
3. **Configure environment variables**  
   Create a `.env` file in the repository root (or export the variables in your shell):
   ```env
   OLLAMA_BASE_URL=http://localhost:11434/v1
   OLLAMA_API_KEY=ollama
   OLLAMA_MODEL=qwen2.5:7b-instruct
   LLM_TEMPERATURE=0.0
   ```
   To use OpenAI or another provider, set `OLLAMA_BASE_URL` to the service URL and provide the corresponding API key.

---

## â–¶ï¸ Run a Simulation
```bash
python main.py --rounds 10 --users 50 --pools 5
```
- `--rounds` â€“ number of epochs to simulate (default `2`).
- `--users` â€“ delegator count (default `2`).
- `--pools` â€“ active stake pools (default `2`).

Each delegator and pool operator triggers an LLM request per decision, so larger runs can take time and consume credits when using paid endpoints.

---

## ğŸ“Š Outputs
Every run creates a timestamped folder under `results/`, e.g. `results/20251015-104646/`, containing:
- `simulation_log.txt` â€“ human-readable round summaries, briefings, and agent actions.
- `simulation_results.json` â€“ structured state snapshots per round, including allocations, rewards, and Gini metrics.

The console also streams delegation decisions and the latest inequality metrics to help monitor long simulations.

---

## âš™ï¸ Customize the Model
- **CLI parameters** â€“ Adjust rounds, users, and pools per invocation.
- **Network constants** â€“ Tweak `TOTAL_REWARDS`, `S_OPT`, and `A0` in `constants.py` to explore alternative reward curves.
- **Stake distribution** â€“ Update `generate_powerlaw_stakes` in `simulation.py` (alpha, min/max stake, seed) to change the initial wealth profile.
- **Agent personas** â€“ Edit persona weights/prompts in `simulation.py`, `user_agents.py`, and `pool_agents.py` to model new behaviors.
- **LLM configuration** â€“ Override `OLLAMA_MODEL`, `OLLAMA_BASE_URL`, `OLLAMA_API_KEY`, or `LLM_TEMPERATURE` in the environment.

---

## â—ï¸ Notes
- The simulation is synchronous and runs entirely on the local machine; provide a responsive LLM endpoint to keep rounds moving.
- Logs are rewritten after each round to avoid partial files; keep the process running until completion to capture the full history.
- The repository ignores the `results/` directory by default. Add generated artifacts to version control only if you need to share them.

---

## ğŸ“„ License
MIT License

---

# å¡å°”è¾¾è¯ºè´¨æŠ¼æ± æ¨¡æ‹Ÿ

è¯¥ä»“åº“å®ç°äº†ä¸€ä¸ªä¾èµ–å¤§è¯­è¨€æ¨¡å‹çš„å¤šè½® Cardano è´¨æŠ¼æ± æ¨¡æ‹Ÿã€‚è´¨æŠ¼æ± è¿è¥è€…ä¼šæ ¹æ®å¸‚åœºä¿¡å·è°ƒæ•´å‚æ•°ï¼Œå§”æ‰˜è€…ä¼šé‡æ–°åˆ†é…è´¨æŠ¼ï¼Œç³»ç»Ÿé€è½®è®°å½•ç½‘ç»œåŠ¨æ€ã€‚

---

## ğŸš€ æ ¸å¿ƒç‰¹ç‚¹
- å¤šè½®åšå¼ˆç¯å¢ƒï¼šå§”æ‰˜è€…ä¸è¿è¥è€…éƒ½ä¼šå“åº”ç½‘ç»œé€šæŠ¥åšå‡ºå†³ç­–ã€‚
- è´¨æŠ¼æ± ä¸å§”æ‰˜è€…å‡ç”±è®¾å®šçš„äººæ ¼é©±åŠ¨ï¼Œé€šè¿‡ OpenAI å…¼å®¹æ¥å£è°ƒç”¨ LLM ç»™å‡ºç†ç”±ä¸æ“ä½œã€‚
- å§”æ‰˜è€…åˆå§‹èµ„äº§éµå¾ªå¯é…ç½®çš„å¹‚å¾‹åˆ†å¸ƒï¼Œå¹¶å¯åœ¨æ¯è½®æŠŠç­¹ç æ‹†åˆ†åˆ°å¤šä¸ªæ± ã€‚
- æ¯æ¬¡è¿è¡Œéƒ½ä¼šç”Ÿæˆæ—¥å¿—ã€ç»“æ„åŒ– JSON å†å²ï¼Œä»¥åŠç”¨äºè¡¡é‡ä¸å¹³ç­‰çš„ Gini ç³»æ•°ã€‚

---

## ğŸ“‚ ç›®å½•ç»“æ„
- `main.py`ï¼šå‘½ä»¤è¡Œå…¥å£ï¼Œè§£æå‚æ•°å¹¶å¯åŠ¨æ¨¡æ‹Ÿã€‚
- `simulation.py`ï¼šç»Ÿç­¹æ¯ä¸€è½®ï¼Œæ„å»ºç½‘ç»œé€šæŠ¥ï¼Œæ±‡æ€»å¥–åŠ±ï¼Œå¹¶æŠŠç»“æœå†™å…¥ `results/<timestamp>/`ã€‚
- `pool_agents.py`ï¼šåŸºäºäººæ ¼çš„è´¨æŠ¼æ± è¿è¥è€…ï¼Œå€ŸåŠ© LLM è°ƒæ•´ pledgeã€margin ä¸ costã€‚
- `user_agents.py`ï¼šå§”æ‰˜è€…äººæ ¼ä¸åˆ†é…ç­–ç•¥å®ç°ã€‚è¿è¡Œå‰è¯·ç¡®è®¤è¯¥æ¨¡å—å¯ç”¨ã€‚
- `constants.py`ï¼šCardano å¥–åŠ±å…¬å¼æ‰€éœ€çš„ç½‘ç»œå¸¸é‡ï¼ˆ`TOTAL_REWARDS`ã€`S_OPT`ã€`A0`ï¼‰ã€‚

---

## ğŸ“¦ ç¯å¢ƒè¦æ±‚
- Python 3.10 åŠä»¥ä¸Šç‰ˆæœ¬ã€‚
- è¿è¡Œ `pip install -r requirements.txt` å®‰è£…ä¾èµ–ã€‚  
  å¦‚æœ `user_agents.py` ç”¨åˆ°äº† `pydantic`ï¼Œè¯·é¢å¤–å®‰è£…è¯¥åº“ã€‚
- ä¸€ä¸ª OpenAI å…¼å®¹çš„æ¨ç†æ¥å£ï¼›é»˜è®¤ä½¿ç”¨æœ¬åœ° Ollama æœåŠ¡ã€‚

---

## ğŸ”§ åˆå§‹åŒ–
1. **å…‹éš†ä»“åº“**
   ```bash
   git clone <repo-url>
   cd Cardano
   ```
2. **å®‰è£…ä¾èµ–**
   ```bash
   pip install -r requirements.txt
   ```
3. **é…ç½®ç¯å¢ƒå˜é‡**  
   åœ¨ä»“åº“æ ¹ç›®å½•åˆ›å»º `.env`ï¼ˆæˆ–ç›´æ¥åœ¨ shell ä¸­å¯¼å‡ºï¼‰ï¼š
   ```env
   OLLAMA_BASE_URL=http://localhost:11434/v1
   OLLAMA_API_KEY=ollama
   OLLAMA_MODEL=qwen2.5:7b-instruct
   LLM_TEMPERATURE=0.0
   ```
   å¦‚éœ€è°ƒç”¨ OpenAI ç­‰å¤–éƒ¨æœåŠ¡ï¼Œè¯·å°† `OLLAMA_BASE_URL` æ”¹ä¸ºå¯¹åº”åœ°å€å¹¶æä¾›æœ‰æ•ˆçš„ API Keyã€‚

---

## â–¶ï¸ è¿è¡Œæ¨¡æ‹Ÿ
```bash
python main.py --rounds 10 --users 50 --pools 5
```
- `--rounds`ï¼šæ¨¡æ‹Ÿè½®æ•°ï¼ˆé»˜è®¤ `2`ï¼‰ã€‚
- `--users`ï¼šå§”æ‰˜è€…æ•°é‡ï¼ˆé»˜è®¤ `2`ï¼‰ã€‚
- `--pools`ï¼šè´¨æŠ¼æ± æ•°é‡ï¼ˆé»˜è®¤ `2`ï¼‰ã€‚

æ¯ä½å§”æ‰˜è€…ä¸è¿è¥è€…åœ¨æ¯è½®éƒ½ä¼šè§¦å‘ä¸€æ¬¡ LLM è¯·æ±‚ï¼Œè§„æ¨¡è¾ƒå¤§çš„å®éªŒéœ€è¦æ›´å¤šæ—¶é—´ä¸ç®—åŠ›ï¼ˆæˆ– API é¢åº¦ï¼‰ã€‚

---

## ğŸ“Š è¾“å‡ºç»“æœ
è¿è¡Œç»“æŸåä¼šåœ¨ `results/` ä¸‹ç”Ÿæˆæ—¶é—´æˆ³ç›®å½•ï¼ˆä¾‹å¦‚ `results/20251015-104646/`ï¼‰ï¼ŒåŒ…å«ï¼š
- `simulation_log.txt`ï¼šä¾¿äºé˜…è¯»çš„è½®æ¬¡è®°å½•ã€å¹¿æ’­å†…å®¹ä¸ä»£ç†è¡Œä¸ºã€‚
- `simulation_results.json`ï¼šç»“æ„åŒ–çš„è½®æ¬¡å¿«ç…§ï¼Œæ¶µç›–å§”æ‰˜åˆ†é…ã€å¥–åŠ±ä¸ Gini æŒ‡æ ‡ã€‚

å‘½ä»¤è¡Œä¼šå®æ—¶è¾“å‡ºå§”æ‰˜åˆ†é…ä¸æœ€æ–°çš„ Gini ç³»æ•°ï¼Œæ–¹ä¾¿ç›‘æ§é•¿æ—¶é—´è¿è¡Œçš„å®éªŒã€‚

---

## âš™ï¸ è‡ªå®šä¹‰é€‰é¡¹
- **å‘½ä»¤è¡Œå‚æ•°**ï¼šæŒ‰éœ€è°ƒæ•´è½®æ•°ã€ç”¨æˆ·å’Œè´¨æŠ¼æ± æ•°é‡ã€‚
- **ç½‘ç»œå¸¸é‡**ï¼šåœ¨ `constants.py` ä¿®æ”¹ `TOTAL_REWARDS`ã€`S_OPT`ã€`A0` ä»¥æ¢ç´¢ä¸åŒå¥–åŠ±æ›²çº¿ã€‚
- **ç­¹ç åˆ†å¸ƒ**ï¼šåœ¨ `simulation.py` çš„ `generate_powerlaw_stakes` ä¸­è°ƒæ•´å¹‚å¾‹å‚æ•°ã€æœ€å°/æœ€å¤§å€¼ä¸éšæœºç§å­ã€‚
- **äººæ ¼ä¸æç¤ºè¯**ï¼šåœ¨ `simulation.py`ã€`user_agents.py`ã€`pool_agents.py` ä¸­ä¿®æ”¹äººæ ¼æ¯”ä¾‹å’Œæç¤ºå†…å®¹ã€‚
- **LLM è®¾ç½®**ï¼šé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›– `OLLAMA_MODEL`ã€`OLLAMA_BASE_URL`ã€`OLLAMA_API_KEY`ã€`LLM_TEMPERATURE`ã€‚

---

## â—ï¸ ä½¿ç”¨æç¤º
- æ¨¡æ‹Ÿä¸ºåŒæ­¥æ‰§è¡Œï¼Œéœ€è¦ç¨³å®šã€å“åº”å¿«çš„ LLM æœåŠ¡ä»¥ä¿è¯æ¯è½®é¡ºåˆ©è¿è¡Œã€‚
- æ—¥å¿—æ–‡ä»¶ä¼šåœ¨æ¯è½®ç»“æŸåæ•´ä½“é‡å†™ï¼›è¯·åœ¨è¿è¡Œç»“æŸåå†è¯»å–ç»“æœä»¥é¿å…æˆªæ–­ã€‚
- ä»“åº“é»˜è®¤å¿½ç•¥ `results/`ï¼›è‹¥éœ€å…±äº«å®éªŒäº§å‡ºï¼Œå¯è‡ªè¡ŒæŠŠéœ€è¦çš„æ–‡ä»¶çº³å…¥ç‰ˆæœ¬æ§åˆ¶ã€‚

---

## ğŸ“„ è®¸å¯è¯
MIT License
