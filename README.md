# Cardano Stake Pool Simulation

This project simulates a multi-round market where Cardano delegators and stake-pool operators evolve strategies with the help of a locally hosted LLM served from Ollama. Each agent reasons about noisy recent performance, produces structured text outputs, and follows built-in behavioural guardrails (limited memory, switching friction, conservative fee adjustments). The repository includes data logging utilities and analysis helpers for inspecting the simulation trails.

---

## ğŸš€ Quick Reference

- **Python version:** 3.13 (see `.venv/`)
- **LLM backend:** Local Ollama model (`OLLAMA_MODEL` env var, default `llama3`)
- **Entry point:** `python main.py`
- **Outputs:** Timestamped folders under `results/`

---

## ğŸ“¦ Environment Setup

1. **Clone the repository** (or drop the files into your workspace).
2. **Create / refresh the virtual environment** (Python 3.13):
   ```bash
   python3.13 -m venv .venv
   source .venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
3. **Start Ollama** (if not already running):
   ```bash
   ollama serve
   ```
4. **Pull the model** you plan to use (defaults to `llama3`). For other choices set `OLLAMA_MODEL` in your shell or `.env`:
   ```bash
   ollama pull llama3
   export OLLAMA_MODEL=llama3
   ```
5. **Populate `.env`** (optional). The simulation loads `.env` automatically, so set extra knobs here (e.g., `OLLAMA_MODEL`, custom run identifiers).

---

## ğŸ§  Agent Workflow Overview

The simulation coordinates users (delegators) and pool operators across repeated rounds. At each round:

1. **Summaries Compile**
   - Pool and user states are aggregated into natural language summaries (stake, rewards, margins, etc.).

2. **Delegator Decisions** (`user_agents.py`)
   - Every cohort receives a system prompt describing its persona, limited to a rolling history window and explicit switching friction.
   - The user prompt provides current pool metrics, the last few rounds of earnings, and a brief record of prior allocations.
   - The Ollama model replies with:
     ```
     THOUGHT: ...reasoning...
     SELECTIONS: POOL1::value, POOL2::value
     ```
   - A regex parser extracts `POOLn::amount` pairs and stores them as JSON for downstream accounting. Most rounds only a small share of cohorts rebalance, matching the configured migration rate.

3. **Pool Operator Updates** (`pool_agents.py`)
   - Similar structure, but the system prompt enforces â‰¤5% parameter tweaks and acknowledges noisy telemetry.
   - LLM-managed pools respond with:
     ```
     THOUGHT: ...analysis...
     PARAMS: PLEDGE::value, MARGIN::value, COST::value
     ```
   - Parsed values adjust the poolâ€™s configuration for the next epoch (clamped to the small-step policy); invalid responses fall back to the previous settings.

4. **Reward & Profit Calculation** (`simulation.py`)
   - Delegated stake totals feed into Cardano-inspired reward formulas using `TOTAL_REWARDS`, `S_OPT`, and `A0`, then a light 1% Gaussian noise is injected to mimic real-world volatility.
   - User rewards and pool profits are recorded; agents append round outcomes to their limited histories.

5. **Structural Events**
   - Every configurable interval (default 50 rounds) a â€œshockâ€ nudges fees upward and trims rewards, forcing strategies to re-evaluate.

6. **Persistence**
   - Each run streams logs to `results/<timestamp>/simulation_log.txt` and continuously refreshes `simulation_results.json`, so partial progress survives interruptions.
     - `simulation_log.txt` â€“ human-readable round-by-round trace (thoughts, decisions, rewards).
     - `simulation_results.json` â€“ structured data for external analysis pipelines.

---

## â–¶ï¸ Running a Simulation

1. Activate the environment:
   ```bash
   source .venv/bin/activate
   ```
2. Launch the run with desired scale:
   ```bash
   python main.py --rounds 100 --users 30 --pools 80
   ```
   - `--rounds` â€“ number of epochs (50â€“300 recommended)
   - `--users` â€“ delegator cohorts (treat as grouped users, default 30)
   - `--pools` â€“ stake pools (only a subset may use LLM-driven strategies)
3. Inspect the generated `results/<timestamp>/` directory for the logs and JSON payload.
4. Optional: craft custom scripts to post-process the JSON or visualise trends.

---

## ğŸ”§ Customisation Tips

- **Model Choice:** Set `OLLAMA_MODEL` (env or `.env`) to switch to another local model.
- **Persona Prompts:** Adjust persona text and message templates inside `prompts.py`; tweak update frequencies or migration probabilities in `user_agents.py` / `pool_agents.py` if your cohorts need different inertia levels.
- **Economics:** Modify constants in `constants.py` to explore alternative network reward parameters.
- **Environment Knobs:** Override defaults via env vars (e.g., `CARDANO_USER_HISTORY_WINDOW`, `CARDANO_REWARD_NOISE_STD`, `CARDANO_SHOCK_INTERVAL`) to explore different market frictions.
- **Logging:** Extend `simulation.py` to capture extra telemetry (e.g., raw thoughts) if you need richer analytics.

---

## âœ… Verification

- Compile check: `python -m compileall Cardano`
- LLM availability: `curl http://localhost:11434/api/tags` (ensures Ollama is serving models)

---

## ğŸ“„ License

MIT License

---

## ğŸ‡¨ğŸ‡³ ä¸­æ–‡å¯¹ç…§æŒ‡å—

### é¡¹ç›®æ¦‚è¿°
æœ¬é¡¹ç›®åˆ©ç”¨éƒ¨ç½²åœ¨æœ¬åœ°çš„ Ollama æ¨¡å‹ï¼Œæ¨¡æ‹Ÿ Cardano å§”æ‰˜äººå’Œè´¨æŠ¼æ± è¿è¥è€…åœ¨å¤šè½®å¸‚åœºä¸­çš„ç­–ç•¥æ¼”åŒ–ã€‚æ¯ä½æ™ºèƒ½ä½“åªåŸºäºæœ€è¿‘çª—å£çš„å™ªå£°æ•°æ®è¿›è¡Œåˆ†æï¼Œè¾“å‡ºå›ºå®šæ ¼å¼çš„æ–‡æœ¬ï¼Œå¹¶éµå¾ªå†…ç½®çš„è¡Œä¸ºçº¦æŸï¼ˆè¿ç§»æ‘©æ“¦ã€å°æ­¥è°ƒå‚ç­‰ï¼‰ã€‚

### å¿«é€Ÿå‚è€ƒ
- Python ç‰ˆæœ¬ï¼š3.13ï¼ˆä½äº `.venv/` è™šæ‹Ÿç¯å¢ƒï¼‰
- æ¨¡å‹åç«¯ï¼šæœ¬åœ° Ollamaï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ `OLLAMA_MODEL` æŒ‡å®šï¼Œé»˜è®¤ `llama3`ï¼‰
- å…¥å£è„šæœ¬ï¼š`python main.py`
- è¾“å‡ºç›®å½•ï¼š`results/` ä¸‹çš„æ—¶é—´æˆ³å­ç›®å½•

### ç¯å¢ƒé…ç½®æ­¥éª¤
1. å…‹éš†ä»“åº“æˆ–å°†æ–‡ä»¶æ”¾å…¥å·¥ä½œç›®å½•ã€‚
2. åˆ›å»ºå¹¶æ¿€æ´» Python 3.13 è™šæ‹Ÿç¯å¢ƒï¼Œå®‰è£…ä¾èµ–ï¼š
   ```bash
   python3.13 -m venv .venv
   source .venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
3. å¯åŠ¨ Ollama æœåŠ¡ï¼š`ollama serve`
4. æ‹‰å–æ‰€éœ€æ¨¡å‹å¹¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚ `OLLAMA_MODEL=llama3`ï¼‰ã€‚
5. å¯åœ¨ `.env` ä¸­é…ç½®é¢å¤–å‚æ•°ï¼Œç¨‹åºä¼šè‡ªåŠ¨åŠ è½½ã€‚

### æ™ºèƒ½ä½“å·¥ä½œæµ
1. ç”Ÿæˆå½“å‰è½®æ¬¡çš„æ± å­å’Œç”¨æˆ·æ‘˜è¦ã€‚
2. å§”æ‰˜äººæ ¹æ®ç³»ç»Ÿæç¤ºã€äººè®¾å’Œå†å²è®°å½•ï¼Œè¾“å‡º `THOUGHT` ä¸ `SELECTIONS`ï¼Œç¨‹åºç”¨æ­£åˆ™è§£æ `POOLn::æ•°å€¼`ã€‚
3. è´¨æŠ¼æ± è¿è¥è€…è¾“å‡º `THOUGHT` ä¸ `PARAMS`ï¼Œè§£æå‡ºæ–°çš„ pledgeã€marginã€costã€‚
4. `simulation.py` æŒ‰ Cardano å¥–åŠ±å…¬å¼è®¡ç®—æ”¶ç›Šä¸åˆ©æ¶¦ï¼Œå¹¶å†™å…¥å†å²ã€‚
5. æ¯éš”å›ºå®šè½®æ¬¡è§¦å‘ç»“æ„æ€§å†²å‡»ï¼ˆé»˜è®¤ 50 è½®ï¼‰ï¼Œä¾‹å¦‚æ‰‹ç»­è´¹ä¸Šè°ƒæˆ–æ”¶ç›Šä¸‹è°ƒï¼Œä¿ƒä½¿ç­–ç•¥é‡æ–°è¯„ä¼°ã€‚
6. ç”Ÿæˆæ—¥å¿—ä¸ JSON æ•°æ®ï¼Œä¿å­˜åœ¨ `results/<timestamp>/`ã€‚

### è¿è¡Œä»¿çœŸ
```bash
source .venv/bin/activate
python main.py --rounds 100 --users 30 --pools 80
```
å‚æ•°å«ä¹‰ï¼š`--rounds` ä¸ºè½®æ¬¡æ•°ï¼ˆå»ºè®® 50â€“300ï¼‰ï¼Œ`--users` è¡¨ç¤ºå§”æ‰˜äººç¾¤ç»„æ•°é‡ï¼Œ`--pools` ä¸ºè´¨æŠ¼æ± æ•°é‡ã€‚è¿è¡Œè¿‡ç¨‹ä¸­æ—¥å¿—ä¼šå®æ—¶å†™å…¥ç£ç›˜ï¼Œå¯åœ¨ä¸­æ–­åç»§ç»­åˆ†æã€‚

### è‡ªå®šä¹‰å»ºè®®
- ä¿®æ”¹ `OLLAMA_MODEL` ä»¥åˆ‡æ¢æœ¬åœ°æ¨¡å‹ã€‚
- æç¤ºæ–‡æ¡ˆé›†ä¸­åœ¨ `prompts.py`ï¼Œå¯æ ¹æ®éœ€æ±‚ä¿®æ”¹ï¼›è‹¥æƒ³è°ƒæ•´ä¸åŒäººç¾¤çš„æƒ¯æ€§æˆ–æ›´æ–°é¢‘ç‡ï¼Œå¯åœ¨ `user_agents.py`ã€`pool_agents.py` ä¸­ä¿®æ”¹ç›¸å…³å‚æ•°ã€‚
- åœ¨ `constants.py` ä¸­ä¿®æ”¹ç»æµå‚æ•°ï¼Œä¾‹å¦‚ `TOTAL_REWARDS`ã€`S_OPT`ã€`A0`ã€‚
- å¯é€šè¿‡ç¯å¢ƒå˜é‡ï¼ˆå¦‚ `CARDANO_USER_HISTORY_WINDOW`ã€`CARDANO_REWARD_NOISE_STD`ã€`CARDANO_SHOCK_INTERVAL`ï¼‰è°ƒèŠ‚è®°å¿†çª—å£ã€å™ªå£°å’Œå†²å‡»é¢‘ç‡ã€‚
- å¦‚éœ€æ›´å¤šæ—¥å¿—ï¼Œå¯æ‰©å±• `simulation.py`ã€‚

### éªŒè¯æ­¥éª¤
- è¯­æ³•æ£€æŸ¥ï¼š`python -m compileall Cardano`
- ç¡®è®¤æ¨¡å‹æœåŠ¡ï¼š`curl http://localhost:11434/api/tags`

### è®¸å¯è¯
MIT è®¸å¯åè®®
